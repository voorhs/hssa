{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ilya/repos/hssa/VENV/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-12 20:25:34.185719: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 20:25:34.871697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Some weights of HSSAModel were not initialized from the model checkpoint at microsoft/mpnet-base and are newly initialized: ['mpnet.encoder.layer.8.attention.bpooler.dense.weight', 'mpnet.encoder.layer.1.attention.bpooler.dense.bias', 'mpnet.embeddings.turn_embeddings.weight', 'mpnet.encoder.layer.7.attention.bpooler.dense.weight', 'mpnet.encoder.layer.6.attention.bpooler.dense.weight', 'mpnet.encoder.layer.2.attention.bpooler.dense.bias', 'mpnet.encoder.layer.10.attention.bpooler.dense.bias', 'mpnet.encoder.layer.7.attention.bpooler.dense.bias', 'mpnet.encoder.layer.4.attention.bpooler.dense.weight', 'mpnet.encoder.layer.5.attention.bpooler.dense.bias', 'mpnet.encoder.layer.6.attention.bpooler.dense.bias', 'mpnet.encoder.layer.5.attention.bpooler.dense.weight', 'mpnet.encoder.layer.9.attention.bpooler.dense.bias', 'mpnet.encoder.layer.1.attention.bpooler.dense.weight', 'mpnet.encoder.layer.0.attention.bpooler.dense.bias', 'mpnet.encoder.layer.11.attention.bpooler.dense.weight', 'mpnet.encoder.layer.11.attention.bpooler.dense.bias', 'mpnet.encoder.layer.10.attention.bpooler.dense.weight', 'mpnet.encoder.layer.8.attention.bpooler.dense.bias', 'mpnet.encoder.layer.4.attention.bpooler.dense.bias', 'mpnet.encoder.layer.9.attention.bpooler.dense.weight', 'mpnet.encoder.layer.2.attention.bpooler.dense.weight', 'mpnet.encoder.layer.3.attention.bpooler.dense.bias', 'mpnet.encoder.layer.3.attention.bpooler.dense.weight', 'mpnet.encoder.layer.0.attention.bpooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from hssa import HSSAModel, HSSAConfig\n",
    "\n",
    "model = HSSAModel.from_pretrained('microsoft/mpnet-base', config=HSSAConfig(max_turn_embeddings=20), device_map='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'MPNetTokenizer'. \n",
      "The class this function is called from is 'HSSATokenizer'.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from hssa import HSSATokenizer\n",
    "\n",
    "tok = HSSATokenizer.from_pretrained('microsoft/mpnet-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30527, 30528]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.additional_special_tokens_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 30529. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30529, 768)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embeddings(\n",
       "  (word_embeddings): Embedding(30529, 768)\n",
       "  (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "  (turn_embeddings): Embedding(20, 768, padding_idx=1)\n",
       "  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask', 'max_dia_len', 'utterance_mask']),\n",
       " torch.Size([90, 43]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "batch = json.load(open('val_batch.json', 'r'))[:5]\n",
    "tokenized = tok(batch).to('cuda')\n",
    "tokenized.keys(), tokenized['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 43, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**tokenized).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
